{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Notebook_FSDL_lab0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyN0gYYPJt/us2lygeb72ivV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Qind1609/Building_NN_from_Scrath/blob/main/Notebook_FSDL_lab0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deep Learning Fundamentals - Part 1**"
      ],
      "metadata": {
        "id": "8nX20Ob2cC8d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzDjeI2AS5hE"
      },
      "outputs": [],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list | grep tensor"
      ],
      "metadata": {
        "id": "43OOu3tjcCk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list | grep torch"
      ],
      "metadata": {
        "id": "eZS0ZT8sdTlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "vHb51LOsdmgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Basic numerical Computing***"
      ],
      "metadata": {
        "id": "YjW8Vojvd5Ea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x =np.zeros((3,2))\n",
        "x"
      ],
      "metadata": {
        "id": "qRC7j9Oxd4lJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape, x.dtype"
      ],
      "metadata": {
        "id": "QZaPZE1NeZ6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x[0,1] = 1\n",
        "x"
      ],
      "metadata": {
        "id": "1x7jmBevehcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x[:,0] = 2\n",
        "x"
      ],
      "metadata": {
        "id": "soCNY0tEepwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[1,2],[3,4],[5,6]])\n",
        "x"
      ],
      "metadata": {
        "id": "uP2Zn2anezFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([10,20])\n",
        "print(X)\n",
        "print(X.shape, x.shape)\n",
        "\n",
        "#Element-wise sum\n",
        "X+x"
      ],
      "metadata": {
        "id": "Zk5FdPSRfLW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Element-wise multiplication\n",
        "\n",
        "X*x"
      ],
      "metadata": {
        "id": "RKtTstr8fkD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#matrix multiplication\n",
        "\n",
        "X = np.array([[10, 20]]).T\n",
        "mul = x @ X #or np.dot(x,X)\n",
        "mul"
      ],
      "metadata": {
        "id": "hKl1JiqzgOoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Indexing**"
      ],
      "metadata": {
        "id": "jif9oE89hO2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.random.rand(3,2) #matrix 3x2 with random element in standard distribution from 0->1\n",
        "y"
      ],
      "metadata": {
        "id": "izu5YTdThNp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y > 0.5 # return a mask of true and false"
      ],
      "metadata": {
        "id": "0RJd_64_hsmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y[y>0.5]=1 #indexing matrix\n",
        "y"
      ],
      "metadata": {
        "id": "zVCDLMdHh2dW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Basic Ploting**\n"
      ],
      "metadata": {
        "id": "wmMp7uurijTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.set_cmap('gray')\n"
      ],
      "metadata": {
        "id": "YACNlk7jiitw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.random.rand(100,100)\n",
        "plt.matshow(X)\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "id": "Rnp9Pu0ulfDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.linspace(0,100)\n",
        "y = x*5+10\n",
        "plt.plot(x,y,'o-')"
      ],
      "metadata": {
        "id": "XbqFhHy6luAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic Regression"
      ],
      "metadata": {
        "id": "mMTxK7kyoKcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 50\n",
        "d = 1\n",
        "x = np.random.uniform(-1,1,(n,d))\n",
        "weights_true = np.array([[5],])\n",
        "bias_true = np.array([10])\n",
        "\n",
        "#y = 5*x + 10\n",
        "y_true = x@weights_true + bias_true\n",
        "print(f'x: {x.shape}, weights: {weights_true.shape}, bias: {bias_true.shape}, y: {y_true.shape}')\n",
        "\n",
        "plt.plot(x, y_true, marker='x',label='underlying function')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "rLbF65H3oJpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Basic the prediction: Linear**\n"
      ],
      "metadata": {
        "id": "Sh0JsrZNxxUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Linear:\n",
        "    #initial the prediction\n",
        "    def __init__(self, num_input, num_output = 1):\n",
        "        self.weights = np.random.randn(num_input, num_output)*np.sqrt(2./num_input)  #random weights\n",
        "        self.bias = np.zeros((1))\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return x @ self.weights + self.bias\n",
        "linear = Linear(d)\n",
        "y_pred = linear(x)\n",
        "plt.plot(x,y_true, marker = 'x', label = 'underlying function')\n",
        "plt.scatter(x,y_pred, color = 'r', marker='.', label='pre_function')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "-06qN1dCx50u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Basic loss function: MSE**"
      ],
      "metadata": {
        "id": "71-77u-Pz-Cz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#how wrong are these initial predictions?\n",
        "\n",
        "class MSE:\n",
        "    def __call__(self, y_pred,y_true):\n",
        "        self.y_pred = y_pred\n",
        "        self.y_true = y_true\n",
        "        return ((y_true - y_pred)**2).mean()\n",
        "loss = MSE()\n",
        "print(f'Our initial loss is {loss(y_pred, y_true)}')"
      ],
      "metadata": {
        "id": "x4Bq4MZhz9lN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Add back propagation**"
      ],
      "metadata": {
        "id": "ifnDMZrw068Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MSE:\n",
        "    def __call__(self, y_pred,y_true):\n",
        "        self.y_pred = y_pred\n",
        "        self.y_true = y_true\n",
        "        return ((y_true - y_pred)**2).mean()\n",
        "    \n",
        "    def backward(self):\n",
        "        n = self.y_true.shape[0]\n",
        "        self.gradient = 2.*(self.y_pred - self.y_true)/n\n",
        "        return self.gradient\n",
        "    \n",
        "class Linear:\n",
        "    def __init__(self, input_dim: int, num_hidden: int = 1):\n",
        "        self.weights = np.random.randn(input_dim, num_hidden) - 0.5 #distribute from -0.5 - > 0.5\n",
        "        self.bias = np.random.randn(num_hidden) - 0.5\n",
        "\n",
        "    def __call__(self, x):\n",
        "        self.x = x\n",
        "        output = x @ self.weights + self.bias\n",
        "        return output\n",
        "\n",
        "    #y = w*x +b\n",
        "    # => dy/dx = w\n",
        "    #   dy/dw = x\n",
        "    # dy/db = 1\n",
        "\n",
        "    def backward(self, gradient):\n",
        "        self.weights_gradient = self.x.T @ gradient\n",
        "        self.bias_gradient = gradient.sum(axis=0)\n",
        "        self.x_gradient = gradient @ self.weights.T\n",
        "        return self.x_gradient\n",
        "    \n",
        "    def update(self,lr):\n",
        "        self.weights = self.weights - lr*self.weights_gradient\n",
        "        self.bias = self.bias - lr*self.bias_gradient"
      ],
      "metadata": {
        "id": "qBG1xCE406CV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = MSE()\n",
        "linear = Linear(d) #initalize \n",
        "y_pred = linear(x) #call\n",
        "print(loss(y_pred, y_true))\n",
        "loss_gradient = loss.backward()\n",
        "linear.backward(loss_gradient)\n",
        "linear.update(0.1)\n",
        "y_pred = linear(x) #call\n",
        "print(loss(y_pred, y_true))"
      ],
      "metadata": {
        "id": "m-5moXbgwdHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training**\n",
        "    "
      ],
      "metadata": {
        "id": "96GK8nd5ysQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(x, y_true,marker='x', label = 'underlying function')\n",
        "\n",
        "loss = MSE()\n",
        "linear = Linear(d)\n",
        "\n",
        "num_epochs = 60\n",
        "lr = 0.1\n",
        "for epoch in range(num_epochs):\n",
        "    y_pred = linear(x)\n",
        "    loss_value = loss(y_pred, y_true)\n",
        "\n",
        "    if epoch % 5 == 0: #print, plot after every 5 epochs\n",
        "        print(f'Epoch {epoch}, loss {loss_value}')\n",
        "        plt.plot(x, y_pred.squeeze(), label = f'Epoch {epoch}')\n",
        "    gradient_from_loss = loss.backward()\n",
        "    linear.backward(gradient_from_loss)\n",
        "    linear.update(lr)\n",
        "\n",
        "plt.legend(bbox_to_anchor = (1.04,1), loc =\"upper left\")"
      ],
      "metadata": {
        "id": "rkk5P-OFynht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2-D of x\n",
        "\n",
        "n = 100\n",
        "d = 2\n",
        "x = np.random.uniform(-1,1,(n,d))\n",
        "# y = w*x + b\n",
        "# y = w0 * x0 + w1 * x1 + b\n",
        "# y = w@x +b\n",
        "\n",
        "weights_true = np.array([[2,-1]]).T  \n",
        "bias_true = np.array([0.5])  #y = 2*x0 - x1 + 0.5\n",
        "print(x.shape, weights_true.shape, bias_true.shape)\n",
        "\n",
        "y_true =  x @ weights_true + bias_true\n",
        "print(f'x: {x.shape}, weights: {weights_true.shape}, bias: {bias_true.shape}, y: {y_true.shape}')\n",
        "\n",
        "def plot_3d(x,y,y_pred = None):\n",
        "    import matplotlib.pyplot as plt\n",
        "    from mpl_toolkits.mplot3d import Axes3D\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111,projection = '3d')\n",
        "    ax.scatter(x[:,0],x[:,1],y, label = 'underlying function')\n",
        "    if y_pred is not None:\n",
        "        ax.scatter(x[:,0],x[:,1], y_pred, label = 'our function')\n",
        "    plt.legend()\n",
        "\n",
        "plot_3d(x,y_true)"
      ],
      "metadata": {
        "id": "Kr0EvDjP1lIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = MSE()\n",
        "linear = Linear(2)\n",
        "y_pred = linear(x)\n",
        "print(loss(y_pred, y_true))\n",
        "fig = plot_3d(x,y_true,y_pred)"
      ],
      "metadata": {
        "id": "JBiOnSN_7mYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Callable\n",
        "def fit(x: np.ndarray, y: np.ndarray, model: Callable, loss: Callable, lr: float, num_epochs: int):\n",
        "    for epoch in range(num_epochs):\n",
        "        y_pred = model(x)\n",
        "        loss_value = loss(y_pred, y)\n",
        "        print(f'Epoch {epoch}, loss {loss_value}')\n",
        "        gradient_from_loss = loss.backward()\n",
        "        model.backward(gradient_from_loss)\n",
        "        model.update(lr)\n",
        "\n",
        "fit(x,y_true,model = linear, loss=loss, lr = 0.1, num_epochs = 60)\n",
        "plot_3d(x,y_true, linear(x))"
      ],
      "metadata": {
        "id": "ldBSl3eC8UI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Basic Regression with a Multi-layer Perceptron or Neural Network**"
      ],
      "metadata": {
        "id": "yh65z_T_9tCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Non linear function\n",
        "n = 200\n",
        "d = 2 \n",
        "x = np.random.uniform(-1,1,(n,d))\n",
        "\n",
        "weights_true = np.array([[5,1]]).T\n",
        "bias_true = np.array([10])\n",
        "\n",
        "y_true = (x**2) @ weights_true + x @ weights_true + bias_true\n",
        "print(f'x: {x.shape}, weights: {weights_true.shape}, bias: {bias_true.shape}, y: {y_true.shape}')\n",
        "\n",
        "plot_3d(x,y_true)"
      ],
      "metadata": {
        "id": "FE6pWvnW9rgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#try to approximate this function by linear regression\n",
        "\n",
        "loss = MSE()\n",
        "linear = Linear(d)\n",
        "fit(x, y_true, model = linear, loss = loss, lr = 0.1, num_epochs = 40)\n",
        "plot_3d(x,y_true, linear(x))"
      ],
      "metadata": {
        "id": "ZC4V2_bHceoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Non-Linearity : ReLu**"
      ],
      "metadata": {
        "id": "q5oUt5iuc6vY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReLu:\n",
        "    def __call__(self, input_):\n",
        "        self.input_ = input_\n",
        "        self.output = np.clip(self.input_,0,None)\n",
        "        return self.output\n",
        "        \n",
        "    def backward(self, output_gradient):\n",
        "        self.input_gradient = (self.input_ > 0) * output_gradient\n",
        "        return self.input_gradient\n",
        "\n",
        "relu = ReLu()\n",
        "input_ = np.expand_dims(np.array([1,0.5,0,-0.5,-1]),-1)\n",
        "print(relu(input_))\n",
        "print(relu.backward(input_))"
      ],
      "metadata": {
        "id": "livV6wfWc6PW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model:\n",
        "    def __init__(self, input_dim, num_hidden):\n",
        "        self.linear1 = Linear(input_dim, num_hidden)  #multiply matrix random weights \n",
        "        self.relu = ReLu()\n",
        "        self.linear2 = Linear(num_hidden, 1)       # mtrix random weights\n",
        "    \n",
        "    def __call__(self, x):  \n",
        "        l1 = self.linear1(x)\n",
        "        r = self.relu(l1)\n",
        "        l2 = self.linear2(r)\n",
        "        return l2\n",
        "\n",
        "    def backward(self, output_gradient):\n",
        "        linear2_gradient = self.linear2.backward(output_gradient)\n",
        "        relu_gradient = self.relu.backward(linear2_gradient)\n",
        "        linear1_gradient = self.linear1.backward(relu_gradient)\n",
        "        return linear1_gradient\n",
        "    \n",
        "    def update(self, lr):\n",
        "        self.linear2.update(lr)\n",
        "        self.linear1.update(lr)\n",
        "\n",
        "#test just one forward and backward step\n",
        "\n",
        "loss = MSE()\n",
        "model = Model(d,10)\n",
        "y_pred = model(x)\n",
        "loss_value = loss(y_pred,y_true)\n",
        "loss_gradient = loss.backward()\n",
        "print(loss_value)\n",
        "model.backward(loss_gradient)\n",
        "plot_3d(x,y_true,y_pred)"
      ],
      "metadata": {
        "id": "_1C1m7HZhKD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training\n",
        "fit(x,y_true, model=model,loss = loss , lr = 0.1, num_epochs = 200)\n",
        "plot_3d(x,y_true, model(x))\n"
      ],
      "metadata": {
        "id": "HuJKKr27_Atw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Try with Pytorch instead of coding from scrath**\n"
      ],
      "metadata": {
        "id": "U-BsJwAzCOjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class TorchModel(nn.Module):\n",
        "    def __init__(self, input_dim, num_hidden):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(input_dim, num_hidden)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(num_hidden,1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        l1 = self.linear1(x)\n",
        "        r  = self.relu(l1)\n",
        "        l2 = self.linear2(r)\n",
        "        return l2\n",
        "\n",
        "#inital loss\n",
        "loss = nn.MSELoss()\n",
        "model = TorchModel(d,10)\n",
        "x_tensor = torch.tensor(x).float()\n",
        "y_true_tensor = torch.tensor(y_true).float()\n",
        "y_pred_tensor = model(x_tensor) #call forward\n",
        "loss_value = loss(y_pred_tensor, y_true_tensor)\n",
        "print(loss_value)\n",
        "plot_3d(x_tensor, y_true_tensor, y_pred_tensor.detach())"
      ],
      "metadata": {
        "id": "0OHJx_mWJb4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test just one forward and backward step\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "optimizer.zero_grad()\n",
        "y_pred_tensor = model(x_tensor)\n",
        "loss_value = loss(y_pred_tensor, y_true_tensor)\n",
        "print(loss_value)\n",
        "loss_gradient = loss_value.backward()\n",
        "optimizer.step()\n",
        "\n",
        "y_pred_tensor = model(x_tensor)\n",
        "loss_value = loss(y_pred_tensor, y_true_tensor)\n",
        "print(loss_value)"
      ],
      "metadata": {
        "id": "hvnKed0cM1xF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def torch_fit(x: np.ndarray, y: np.ndarray, model: Callable, loss: Callable, lr: float, num_epochs: int):\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr = lr)\n",
        "    for epoch in range(num_epochs):\n",
        "        optimizer.zero_grad()\n",
        "        y_pred_tensor = model(x_tensor)\n",
        "        loss_value = loss(y_pred_tensor, y_true_tensor)\n",
        "        print(loss_value)\n",
        "        loss_value.backward()\n",
        "        optimizer.step()\n",
        "torch_fit(x_tensor, y_true_tensor, model = model, loss=loss, lr = 0.1, num_epochs = 40)\n",
        "plot_3d(x, y_true, linear(x))\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "zfas_66r-er0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Try with TensorFlow/Keras**"
      ],
      "metadata": {
        "id": "QlcyAB7-AFyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "inputs = keras.Input(shape=(2,))\n",
        "l1 = layers.Dense(10, activation = 'relu', name = 'dense_1')(inputs)\n",
        "outputs = layers.Dense(1, name='regression')(l1)\n",
        "\n",
        "model = keras.Model(inputs = inputs, outputs = outputs)\n",
        "\n",
        "print(model.summary())\n",
        "model.compile(loss = 'mse', optimizer = optimizers.SGD(0.1))\n",
        "\n",
        "model.fit(x,y_true, epochs = 60)\n",
        "\n",
        "y_pred = model.predict(x)\n",
        "plot_3d(x,y_true, model(x))"
      ],
      "metadata": {
        "id": "q8RTpyjaAEnB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}